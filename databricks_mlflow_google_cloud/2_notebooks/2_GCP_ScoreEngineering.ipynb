{"nbformat_minor":4,"cells":[{"source":["#  Engineer and Test the PySpark job (score.py) on GCP Cloud Dataproc to deploy the (Champion) Model (Mlean Flavor) for in-batch\n","\n","This notebook walks through the process of enginner and testing the PySpark job on Cloud Dataproc for deploying the model in batch\n","\n","#### Author: \n","\n","**Nardini, Ivan - Sr. Customer Advisor | CI & Analytics Team | ModelOps & Decisioning**\n","\n","## Setup\n","\n","About the setup:\n","\n","**1. Clone the git repo and set the environment**\n","\n","**2. Create pyspark job for scoring: score.py**\n","\n","**3. Test the script**"],"cell_type":"markdown","metadata":{}},{"source":["## 1. Clone the git repo and set the environment\n","\n","Mleap needs jar files (inside SPARK_HOME/jars). \n","\n","Some of them are:\n","\n","1. mleap-spark-base_xxx.jar\n","2. mleap-core_xxx.jar\n","3. mleap-runtime_xxx.jar\n","4. mleap-spark_xxx.jar\n","5. bundle-ml_xxx.jar\n","6. config-0.3.0.jar\n","7. scalapb-runtime_xxx.jar\n","8. mleap-tensor_xxx.jar\n","\n","and then installed using pip mleap - MLeap Python API"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["%%bash\n","cd home\n","git clone https://github.com/IvanNardini/Databricks_MLflow_GCP\n","cp ./Databricks_MLflow_GCP/2_notebooks/output/ModelProjects_Boston_ML_lrModel.zip /tmp/model.zip"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["%%bash\n","pip freeze"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["%%bash\n","pip install mleap==0.15.0\n","pip install pyspark==2.4.5"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["# %%bash\n","# spark-shell --packages ml.combust.mleap:mleap-spark_2.11:0.15.0"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["# %%bash\n","# cp -r /root/.ivy2/jars/*.jar /usr/lib/spark/jars/"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["# Restart Kernel\n","# import os\n","# os._exit(00)"],"outputs":[],"metadata":{}},{"source":["## 2. Create Pyspark job (score.py) for scoring"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["os.chdir('./Databricks_MLflow_GCP/2_notebooks/output/')\n","os.getcwd()"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["%%writefile score.py\n","\n","#!/usr/bin/python\n","\n","import numpy as np\n","import pandas as pd\n","import pyspark\n","from pyspark import SparkContext\n","from pyspark.sql import SQLContext, SparkSession\n","from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n","from pyspark.ml.feature import VectorAssembler\n","import mleap.pyspark\n","from mleap.pyspark.spark_support import SimpleSparkSerializer\n","from pyspark.ml import PipelineModel\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","\n","import os\n","import sys\n","import argparse\n","import tempfile\n","import warnings\n","\n","\n","def read_data_csv(spark, inputPath_CSV):\n","    \n","    '''\n","    Function to load data in the Spark Session \n","    :param spark: spark session \n","    :param inputPath: path to get the data \n","    :return: df\n","    '''\n","    \n","    print('Trying to read the data...')\n","    \n","    try:\n","        schema = StructType([\n","          StructField('crim',DoubleType(),True),\n","          StructField('zn',DoubleType(),True),\n","          StructField('indus',DoubleType(),True),\n","          StructField('chas',IntegerType(),True),\n","          StructField('nox',DoubleType(),True),\n","          StructField('rm',DoubleType(),True),\n","          StructField('age',DoubleType(),True),\n","          StructField('dis',DoubleType(),True),\n","          StructField('rad',IntegerType(),True),\n","          StructField('tax',IntegerType(),True),\n","          StructField('ptratio',DoubleType(),True),\n","          StructField('b',DoubleType(),True),\n","          StructField('lstat',DoubleType(),True),\n","          StructField('medv',DoubleType(),True)]\n","        )\n","        \n","        df = (spark.read\n","          .option(\"HEADER\", True)\n","          .schema(schema)\n","          .csv(inputPath_CSV))\n","    \n","    except ValueError:\n","        print('At least, one variable format is wrong! Please check the data')\n","      \n","    else:\n","        print('Data to score have been read successfully!')\n","        return df\n","\n","def preprocessing(df):\n","\n","    '''\n","    Function to preprocess data \n","    :param df: A pyspark DataFrame \n","    :return: abt_to_score\n","    '''\n","    \n","    print('Data preprocessing...')\n","\n","    features = df.schema.names[:-1]\n","    assembler_features = VectorAssembler(inputCols=features, outputCol=\"features\")\n","    abt_to_score = assembler_features.transform(df)\n","    \n","    print('Data have been processed successfully!')\n","    return abt_to_score\n","\n","def score_data(abt_to_score, modelPath):\n","    \n","    '''\n","    Function to score data \n","    :param abt_to_score: A pyspark DataFrame to score\n","    :param modelPath: The modelpath associated to .zip mleap flavor\n","    :return: scoredData\n","    '''\n","    print('Scoring process starts...')\n","    \n","    deserializedPipeline = PipelineModel.deserializeFromBundle(\"jar:file:{}\".format(modelPath))\n","    scoredData = deserializedPipeline.transform(abt_to_score)\n","    return scoredData  \n","  \n","def write_output_csv(scoredData, outputPath_CSV):\n","    '''\n","    Function to write predictions\n","    :param scoredData: A pyspark DataFrame of predictions\n","    :param outputPath: The path to write the ouput table\n","    :return: scoredData\n","    '''\n","    print('Writing Prediction in {}'.format(outputPath_CSV))\n","    scoredData.toPandas().to_csv(outputPath_CSV, sep=',', index=False)\n","    return scoredData.toPandas().to_dict()\n","\n","def evaluator(predictions):\n","    \n","    '''\n","    Function to produce some evaluation stats\n","    :param predictions: A pyspark DataFrame of predictions\n","    :return: rmse, mse, r2, mae\n","    '''\n","    evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"medv\")\n","    rmse = evaluator.evaluate(predictions)\n","    mse = evaluator.evaluate(predictions, {evaluator.metricName: \"mse\"})\n","    r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n","    mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n","    \n","    return rmse, mse, r2, mae\n","\n","def main():\n","    \n","    parser = argparse.ArgumentParser(description='Score')\n","    \n","    parser.add_argument('--input', dest=\"inputpath_CSV\",\n","                        required=True, help='Provide the input path of data to score')\n","\n","    #Mleap deserializeFromBundle method does not work with URL on GCP\n","    \n","    # parser.add_argument('--model', dest=\"modelPath\",\n","    #                     required=True, help='Provide the model path to score')\n","    \n","    parser.add_argument('--output', dest=\"outputpath_CSV\",\n","                        required=True, help='Provide the model path to score')\n","\n","    args = parser.parse_args()\n","    input_path_CSV = args.inputpath_CSV\n","    # modelPath = args.modelPath\n","    modelPath = '/tmp/model.zip'\n","    output_path_CSV = args.outputpath_CSV\n","  \n","    try:\n","#         spark = SparkSession \\\n","#         .builder \\\n","#         .master() \\\n","#         .config('spark.jars.packages',\n","#                 'ml.combust.mleap:mleap-spark-base_2.11:0.15.0,ml.combust.mleap:mleap-spark_2.11:0.15.0') \\\n","#         .appName(\"RegressionScoring\") \\\n","#         .getOrCreate()\n","        spark = SparkSession.builder.appName('RegressionScoring').getOrCreate()\n","        spark.sparkContext.setLogLevel(\"OFF\")\n","        print('Created a SparkSession')\n","    \n","    except ValueError:\n","        warnings.warn('Check')\n","  \n","    #Read data\n","    data_to_process = read_data_csv(spark, input_path_CSV)\n","    #Preprocessing\n","    abt = preprocessing(data_to_process)\n","    #Scoring\n","    abt_scored = score_data(abt, modelPath)\n","    #Write data\n","    write_output_csv(abt_scored, output_path_CSV)\n","    #Evaluate Model\n","    evalstats = evaluator(abt_scored)\n","    return evalstats\n","    \n","    \n","if __name__==\"__main__\":\n","    \n","    stats = main()\n","    print('-'*20)\n","    print('Process Log')\n","    print('-'*20)\n","    print('Scoring Job ends successfully!')\n","    print(\"RMSE for the model: {}\".format(stats[0]))\n","    print(\"MSE for the model: {}\".format(stats[1]))\n","    print(\"R2 for the model: {}\".format(stats[2]))\n","    print(\"MAE for the model: {}\".format(stats[3]))\n","    print('Look at the Storage Bucket to get predictions!')\n","    "],"outputs":[],"metadata":{}},{"source":["### 3. Test score.py"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["%%bash\n","python score.py --input \"/home/Databricks_MLflow_GCP/1_data/boston_house_prices.csv\" \\\n","    --output  \"/home/Databricks_MLflow_GCP/1_data/boston_house_prices_scored.csv\" "],"outputs":[],"metadata":{}}],"nbformat":4,"metadata":{"kernelspec":{"display_name":"PySpark","name":"pyspark","language":"python"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","version":"2.7.14","name":"python","file_extension":".py","pygments_lexer":"ipython2","codemirror_mode":{"version":2,"name":"ipython"}},"name":"2_Enginerring","notebookId":3075853380345907}}