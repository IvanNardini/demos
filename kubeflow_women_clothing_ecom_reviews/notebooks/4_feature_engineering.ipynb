{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ambient-hepatitis",
   "metadata": {},
   "source": [
    "# Text Analysis for Women's E-Commerce Clothing Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-fraction",
   "metadata": {},
   "source": [
    "## Libraries and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compliant-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Feature engineering\n",
    "import string\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-palace",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "brown-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = os.path.join(os.pardir, 'data', 'processed')\n",
    "RANDOM_STATE = 8\n",
    "TARGET = 'recommended_ind'\n",
    "TEXT_VARIABLES = ['review_text', 'review_text_processed']\n",
    "FEATURED_DIR = os.path.join(os.pardir, 'data', 'featured')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-toddler",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "clinical-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, filename):\n",
    "    data_path = os.path.join(path, filename)\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "def get_count_words(s):\n",
    "    return len(str(s).split(\" \"))\n",
    "\n",
    "def get_count_char(s):\n",
    "    return sum(len(w) for w in str(s).split(\" \"))\n",
    "\n",
    "def get_count_sents(s):\n",
    "    return len(str(s).split(\".\"))\n",
    "\n",
    "def get_count_exc_marks(s):\n",
    "    return s.count('!')\n",
    "\n",
    "def get_count_question_marks(s):\n",
    "    return s.count('?')\n",
    "    \n",
    "def get_count_pct(s):\n",
    "    return len([w for w in s if w in '\"#$%&\\'()*+,-./:;<=>@[\\\\]^_`{|}~'])\n",
    "\n",
    "def get_count_cap(s):\n",
    "    return sum(1 for w in s if w.isupper())\n",
    "\n",
    "def get_polarity(s):\n",
    "    tb = TextBlob(s)\n",
    "    return tb.sentiment.polarity\n",
    "\n",
    "def get_subjectivity(s):\n",
    "    tb = TextBlob(s)\n",
    "    return tb.sentiment.subjectivity\n",
    "\n",
    "def get_text_features(df, text_var):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # word count\n",
    "    df_copy['word_count'] = df_copy[text_var].apply(get_count_words)\n",
    "    # character count\n",
    "    df_copy['char_count'] = df_copy[text_var].apply(get_count_char)\n",
    "    # sentence count\n",
    "    df_copy['sentence_count'] = df_copy[text_var].apply(get_count_sents)\n",
    "    # count capitals\n",
    "    df_copy['capitals_count'] = df_copy[text_var].apply(get_count_cap)\n",
    "    # count puncts\n",
    "    df_copy['punc_count'] = df_copy[text_var].apply(get_count_pct)\n",
    "    df_copy['exc_marks_count'] = df_copy[text_var].apply(get_count_exc_marks)\n",
    "    df_copy['question_marks_count'] = df_copy[text_var].apply(get_count_question_marks)\n",
    "    # avg word len\n",
    "    df_copy['avg_word_len'] = df_copy['char_count'] / df_copy['word_count']\n",
    "    # avg sentence len\n",
    "    df_copy['avg_sentence_len'] = df_copy['word_count'] / df_copy['sentence_count']\n",
    "    # avg cap\n",
    "    df_copy['avg_cap_len']= df_copy.apply(lambda row: float(row['capitals_count'])/float(row['word_count']), axis=1)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def get_nlp_features(df, text_var):\n",
    "    df_copy = df.copy()\n",
    "    # polarity\n",
    "    df_copy['polarity'] = df_copy[text_var].apply(get_polarity)\n",
    "    # subjectivity\n",
    "    df_copy['subjectivity'] = df_copy[text_var].apply(get_subjectivity)\n",
    "    return df_copy\n",
    "\n",
    "def get_tfidf_df(df, text_cols, tfidf_matrix, cols):\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy.drop(text_cols, axis=1)\n",
    "    tfidf_plain = tfidf_matrix.toarray()\n",
    "    tfidf = pd.DataFrame(tfidf_plain, columns=cols)\n",
    "    tfidf_df = pd.merge(df_copy, tfidf, how=\"left\", left_index=True, right_index=True)\n",
    "    return tfidf_df\n",
    "\n",
    "def save_data(x_df, y_df, path, filename):\n",
    "    df = pd.merge(x_df, y_df, how=\"left\", left_index=True, right_index=True)\n",
    "    data_path = os.path.join(path, filename)\n",
    "    df.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-engineering",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "variable-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(PROCESSED_DIR, 'train_processed.csv')\n",
    "test = load_data(PROCESSED_DIR, 'test_processed.csv')\n",
    "val = load_data(PROCESSED_DIR, 'val_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "minute-animal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_text_processed</th>\n",
       "      <th>recommended_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867</td>\n",
       "      <td>I have been admiring this piece for awhile and...</td>\n",
       "      <td>['admir', 'piec', 'awhil', 'final', 'decid', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081</td>\n",
       "      <td>This dress looks great on me. it gives a slend...</td>\n",
       "      <td>['dress', 'look', 'great', 'give', 'slender', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862</td>\n",
       "      <td>I love this! i agree with previous post that s...</td>\n",
       "      <td>['love', 'agre', 'previou', 'post', 'say', 'mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081</td>\n",
       "      <td>Not sure why this dress was once backordered? ...</td>\n",
       "      <td>['sure', 'dress', 'backord', 'big', 'chest', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>Unlike the other reviewers, i did not have any...</td>\n",
       "      <td>['unlik', 'review', 'problem', 'size', 'fit', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id                                        review_text  \\\n",
       "0          867  I have been admiring this piece for awhile and...   \n",
       "1         1081  This dress looks great on me. it gives a slend...   \n",
       "2          862  I love this! i agree with previous post that s...   \n",
       "3         1081  Not sure why this dress was once backordered? ...   \n",
       "4         1020  Unlike the other reviewers, i did not have any...   \n",
       "\n",
       "                               review_text_processed  recommended_ind  \n",
       "0  ['admir', 'piec', 'awhil', 'final', 'decid', '...                1  \n",
       "1  ['dress', 'look', 'great', 'give', 'slender', ...                1  \n",
       "2  ['love', 'agre', 'previou', 'post', 'say', 'mu...                1  \n",
       "3  ['sure', 'dress', 'backord', 'big', 'chest', '...                0  \n",
       "4  ['unlik', 'review', 'problem', 'size', 'fit', ...                1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-warner",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "sophisticated-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[train.columns.difference([TARGET])]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[test.columns.difference([TARGET])]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "X_val = val[val.columns.difference([TARGET])]\n",
    "y_val = val[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-liquid",
   "metadata": {},
   "source": [
    "### Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "corporate-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text_feats = get_text_features(X_train, TEXT_VARIABLES[0])\n",
    "X_test_text_feats = get_text_features(X_test, TEXT_VARIABLES[0])\n",
    "X_val_text_feats = get_text_features(X_val, TEXT_VARIABLES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "respiratory-raleigh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_text_processed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>capitals_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>exc_marks_count</th>\n",
       "      <th>question_marks_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>avg_cap_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867</td>\n",
       "      <td>I have been admiring this piece for awhile and...</td>\n",
       "      <td>['admir', 'piec', 'awhil', 'final', 'decid', '...</td>\n",
       "      <td>87</td>\n",
       "      <td>371</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.264368</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081</td>\n",
       "      <td>This dress looks great on me. it gives a slend...</td>\n",
       "      <td>['dress', 'look', 'great', 'give', 'slender', ...</td>\n",
       "      <td>22</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.318182</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862</td>\n",
       "      <td>I love this! i agree with previous post that s...</td>\n",
       "      <td>['love', 'agre', 'previou', 'post', 'say', 'mu...</td>\n",
       "      <td>75</td>\n",
       "      <td>284</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.786667</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081</td>\n",
       "      <td>Not sure why this dress was once backordered? ...</td>\n",
       "      <td>['sure', 'dress', 'backord', 'big', 'chest', '...</td>\n",
       "      <td>39</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>Unlike the other reviewers, i did not have any...</td>\n",
       "      <td>['unlik', 'review', 'problem', 'size', 'fit', ...</td>\n",
       "      <td>66</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.878788</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id                                        review_text  \\\n",
       "0          867  I have been admiring this piece for awhile and...   \n",
       "1         1081  This dress looks great on me. it gives a slend...   \n",
       "2          862  I love this! i agree with previous post that s...   \n",
       "3         1081  Not sure why this dress was once backordered? ...   \n",
       "4         1020  Unlike the other reviewers, i did not have any...   \n",
       "\n",
       "                               review_text_processed  word_count  char_count  \\\n",
       "0  ['admir', 'piec', 'awhil', 'final', 'decid', '...          87         371   \n",
       "1  ['dress', 'look', 'great', 'give', 'slender', ...          22          95   \n",
       "2  ['love', 'agre', 'previou', 'post', 'say', 'mu...          75         284   \n",
       "3  ['sure', 'dress', 'backord', 'big', 'chest', '...          39         182   \n",
       "4  ['unlik', 'review', 'problem', 'size', 'fit', ...          66         256   \n",
       "\n",
       "   sentence_count  capitals_count  punc_count  exc_marks_count  \\\n",
       "0               5               1          13                2   \n",
       "1               3               1           3                0   \n",
       "2               7               1           8                1   \n",
       "3               5               1           4                0   \n",
       "4               5               1          10                0   \n",
       "\n",
       "   question_marks_count  avg_word_len  avg_sentence_len  avg_cap_len  \n",
       "0                     0      4.264368         17.400000     0.011494  \n",
       "1                     0      4.318182          7.333333     0.045455  \n",
       "2                     0      3.786667         10.714286     0.013333  \n",
       "3                     1      4.666667          7.800000     0.025641  \n",
       "4                     2      3.878788         13.200000     0.015152  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-catalyst",
   "metadata": {},
   "source": [
    "### More NLP based features \n",
    "\n",
    "**TODO: Add Part to Speech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "simplified-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nlp_feats = get_nlp_features(X_train_text_feats, TEXT_VARIABLES[0])\n",
    "X_test_nlp_feats = get_nlp_features(X_test_text_feats, TEXT_VARIABLES[0])\n",
    "X_val_nlp_feats = get_nlp_features(X_val_text_feats, TEXT_VARIABLES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "wired-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_text_processed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>capitals_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>exc_marks_count</th>\n",
       "      <th>question_marks_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>avg_cap_len</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867</td>\n",
       "      <td>I have been admiring this piece for awhile and...</td>\n",
       "      <td>['admir', 'piec', 'awhil', 'final', 'decid', '...</td>\n",
       "      <td>87</td>\n",
       "      <td>371</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.264368</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.463272</td>\n",
       "      <td>0.659877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081</td>\n",
       "      <td>This dress looks great on me. it gives a slend...</td>\n",
       "      <td>['dress', 'look', 'great', 'give', 'slender', ...</td>\n",
       "      <td>22</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.318182</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.794444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862</td>\n",
       "      <td>I love this! i agree with previous post that s...</td>\n",
       "      <td>['love', 'agre', 'previou', 'post', 'say', 'mu...</td>\n",
       "      <td>75</td>\n",
       "      <td>284</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.786667</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.299444</td>\n",
       "      <td>0.581806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081</td>\n",
       "      <td>Not sure why this dress was once backordered? ...</td>\n",
       "      <td>['sure', 'dress', 'backord', 'big', 'chest', '...</td>\n",
       "      <td>39</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>-0.057937</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>Unlike the other reviewers, i did not have any...</td>\n",
       "      <td>['unlik', 'review', 'problem', 'size', 'fit', ...</td>\n",
       "      <td>66</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.878788</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.591667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id                                        review_text  \\\n",
       "0          867  I have been admiring this piece for awhile and...   \n",
       "1         1081  This dress looks great on me. it gives a slend...   \n",
       "2          862  I love this! i agree with previous post that s...   \n",
       "3         1081  Not sure why this dress was once backordered? ...   \n",
       "4         1020  Unlike the other reviewers, i did not have any...   \n",
       "\n",
       "                               review_text_processed  word_count  char_count  \\\n",
       "0  ['admir', 'piec', 'awhil', 'final', 'decid', '...          87         371   \n",
       "1  ['dress', 'look', 'great', 'give', 'slender', ...          22          95   \n",
       "2  ['love', 'agre', 'previou', 'post', 'say', 'mu...          75         284   \n",
       "3  ['sure', 'dress', 'backord', 'big', 'chest', '...          39         182   \n",
       "4  ['unlik', 'review', 'problem', 'size', 'fit', ...          66         256   \n",
       "\n",
       "   sentence_count  capitals_count  punc_count  exc_marks_count  \\\n",
       "0               5               1          13                2   \n",
       "1               3               1           3                0   \n",
       "2               7               1           8                1   \n",
       "3               5               1           4                0   \n",
       "4               5               1          10                0   \n",
       "\n",
       "   question_marks_count  avg_word_len  avg_sentence_len  avg_cap_len  \\\n",
       "0                     0      4.264368         17.400000     0.011494   \n",
       "1                     0      4.318182          7.333333     0.045455   \n",
       "2                     0      3.786667         10.714286     0.013333   \n",
       "3                     1      4.666667          7.800000     0.025641   \n",
       "4                     2      3.878788         13.200000     0.015152   \n",
       "\n",
       "   polarity  subjectivity  \n",
       "0  0.463272      0.659877  \n",
       "1  0.544444      0.794444  \n",
       "2  0.299444      0.581806  \n",
       "3 -0.057937      0.411111  \n",
       "4  0.420833      0.591667  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nlp_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-extension",
   "metadata": {},
   "source": [
    "### TF-IDF Feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "united-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "tf_idf_vectorizer = tf_idf_vectorizer.fit(X_train_nlp_feats[TEXT_VARIABLES[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "floating-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train_matrix = tf_idf_vectorizer.transform(X_train_nlp_feats[TEXT_VARIABLES[1]])\n",
    "tf_idf_test_matrix = tf_idf_vectorizer.transform(X_test_nlp_feats[TEXT_VARIABLES[1]])\n",
    "tf_idf_val_matrix = tf_idf_vectorizer.transform(X_val_nlp_feats[TEXT_VARIABLES[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "interested-knock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22248x11173 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 578756 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-creator",
   "metadata": {},
   "source": [
    "### TODO: Add Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-machine",
   "metadata": {},
   "source": [
    "### TODO: Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "partial-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_df = get_tfidf_df(X_train_nlp_feats, TEXT_VARIABLES, tf_idf_train_matrix, tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "italic-pepper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>capitals_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>exc_marks_count</th>\n",
       "      <th>question_marks_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>...</th>\n",
       "      <th>zipbutton</th>\n",
       "      <th>ziphoodi</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867</td>\n",
       "      <td>87</td>\n",
       "      <td>371</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.264368</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081</td>\n",
       "      <td>22</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.318182</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862</td>\n",
       "      <td>75</td>\n",
       "      <td>284</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.786667</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081</td>\n",
       "      <td>39</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>66</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.878788</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id  word_count  char_count  sentence_count  capitals_count  \\\n",
       "0          867          87         371               5               1   \n",
       "1         1081          22          95               3               1   \n",
       "2          862          75         284               7               1   \n",
       "3         1081          39         182               5               1   \n",
       "4         1020          66         256               5               1   \n",
       "\n",
       "   punc_count  exc_marks_count  question_marks_count  avg_word_len  \\\n",
       "0          13                2                     0      4.264368   \n",
       "1           3                0                     0      4.318182   \n",
       "2           8                1                     0      3.786667   \n",
       "3           4                0                     1      4.666667   \n",
       "4          10                0                     2      3.878788   \n",
       "\n",
       "   avg_sentence_len  ...  zipbutton  ziphoodi  ziploc  zipper  zipperi  zombi  \\\n",
       "0         17.400000  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "1          7.333333  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "2         10.714286  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "3          7.800000  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "4         13.200000  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "\n",
       "   zone  zooland  zoom  zuma  \n",
       "0   0.0      0.0   0.0   0.0  \n",
       "1   0.0      0.0   0.0   0.0  \n",
       "2   0.0      0.0   0.0   0.0  \n",
       "3   0.0      0.0   0.0   0.0  \n",
       "4   0.0      0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 11186 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dimensional-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_df = get_tfidf_df(X_test_nlp_feats, TEXT_VARIABLES, tf_idf_test_matrix, tf_idf_vectorizer.get_feature_names())\n",
    "tfidf_val_df = get_tfidf_df(X_val_nlp_feats, TEXT_VARIABLES, tf_idf_val_matrix, tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-found",
   "metadata": {},
   "source": [
    "### Scale variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "brutal-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(tfidf_train_df)\n",
    "X_train_scaled = scaler.transform(tfidf_train_df)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=tfidf_train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fifth-chase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>capitals_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>exc_marks_count</th>\n",
       "      <th>question_marks_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>...</th>\n",
       "      <th>zipbutton</th>\n",
       "      <th>ziphoodi</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719269</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252395</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.897010</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.208134</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>0.062092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.715116</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.660287</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.02439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172778</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.897010</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.416268</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.846346</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.593301</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.188131</td>\n",
       "      <td>0.119608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id  word_count  char_count  sentence_count  capitals_count  \\\n",
       "0     0.719269    0.758929    0.868421        0.102564             1.0   \n",
       "1     0.897010    0.178571    0.208134        0.051282             1.0   \n",
       "2     0.715116    0.651786    0.660287        0.153846             1.0   \n",
       "3     0.897010    0.330357    0.416268        0.102564             1.0   \n",
       "4     0.846346    0.571429    0.593301        0.102564             1.0   \n",
       "\n",
       "   punc_count  exc_marks_count  question_marks_count  avg_word_len  \\\n",
       "0    0.216667          0.04878              0.000000      0.252395   \n",
       "1    0.050000          0.00000              0.000000      0.261364   \n",
       "2    0.133333          0.02439              0.000000      0.172778   \n",
       "3    0.066667          0.00000              0.166667      0.319444   \n",
       "4    0.166667          0.00000              0.333333      0.188131   \n",
       "\n",
       "   avg_sentence_len  ...  zipbutton  ziphoodi  ziploc  zipper  zipperi  zombi  \\\n",
       "0          0.160784  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "1          0.062092  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "2          0.095238  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "3          0.066667  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "4          0.119608  ...        0.0       0.0     0.0     0.0      0.0    0.0   \n",
       "\n",
       "   zone  zooland  zoom  zuma  \n",
       "0   0.0      0.0   0.0   0.0  \n",
       "1   0.0      0.0   0.0   0.0  \n",
       "2   0.0      0.0   0.0   0.0  \n",
       "3   0.0      0.0   0.0   0.0  \n",
       "4   0.0      0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 11186 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "later-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(tfidf_test_df)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=tfidf_test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "immune-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = scaler.transform(tfidf_val_df)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=tfidf_val_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-found",
   "metadata": {},
   "source": [
    "## Store Featured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "color-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dfs = [X_train_scaled, X_test_scaled, X_val_scaled]\n",
    "y_dfs = [y_train, y_test, y_val]\n",
    "\n",
    "p = Path(FEATURED_DIR)\n",
    "if not p.exists():\n",
    "    os.mkdir(p)\n",
    "df_names = ['train_abt.csv', 'test_abt.csv', 'val_abt.csv']\n",
    "for x_df, y_df, df_name in zip(X_dfs, y_dfs, df_names):\n",
    "    save_data(x_df, y_df, FEATURED_DIR, df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-anaheim",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
