name: Run generate features
inputs:
- {name: config, type: String}
- {name: mode, type: String}
- {name: bucket, type: String}
- {name: train_path, type: GCSPath}
- {name: test_path, type: GCSPath}
- {name: val_path, type: GCSPath}
outputs:
- {name: train, type: GCSPath}
- {name: test, type: GCSPath}
- {name: val, type: GCSPath}
implementation:
  container:
    image: docker.io/in92/feature_generator:latest
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def run_generate_features(config,
                      mode,
                      bucket,
                      train_path,
                      test_path,
                      val_path):
          # Libraries --------------------------------------------------------------------------------------------------------
          import logging.config
          import yaml
          import sys
          import os
          from src.generate_features import FeaturesGenerator
          from src.helpers import load_data, save_data

          # Settings ---------------------------------------------------------------------------------------------------------
          logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',
                              datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)

          try:
              logging.info('Initializing configuration...')
              stream = open(config, 'r')
              config = yaml.load(stream=stream, Loader=yaml.FullLoader)
              feats_generator = FeaturesGenerator(config=config)

              logging.info('Initiating features engineering process...')
              if mode == 'cloud':
                  output_paths_gcs = []

                  # Train ----------------------------------------------------------------------------------------------------
                  train_data = load_data(input_data=train_path, mode=mode)
                  y_train = train_data[[config['target']]]
                  x_train = train_data[train_data.columns.difference([config['target']])]

                  feats_generator.fit(data=x_train, est_param=config['est_params'][0])
                  x_train_tf_idf_df = feats_generator.transform(data=x_train, est_param=config['est_params'][0])

                  feats_generator.fit(data=x_train_tf_idf_df, est_param=config['est_params'][1])
                  x_train_scaled = feats_generator.transform(data=x_train_tf_idf_df, est_param=config['est_params'][1])

                  train_path_gcs = save_data(x_df=x_train_scaled, y_df=y_train, path=config['featured_path'],
                                               out_data=config['featured_data'][0], mode=mode, bucket=bucket)
                  output_paths_gcs.append(train_path_gcs)

                  # Test - Val -----------------------------------------------------------------------------------------------
                  for input_path, out_filename in zip([test_path, val_path], config['featured_data'][1:]):

                      data = load_data(input_data=input_path, mode=mode)
                      y = data[[config['target']]]
                      x = data[data.columns.difference([config['target']])]

                      x_tf_idf_matrix = feats_generator.transform(data=x, est_param=config['est_params'][0])
                      x_scaled = feats_generator.transform(data=x_tf_idf_matrix, est_param=config['est_params'][1])

                      x_path_gcs = save_data(x_df=x_scaled, y_df=y, path=config['featured_path'],
                                                 out_data=out_filename, mode=mode, bucket=bucket)

                      output_paths_gcs.append(x_path_gcs)

                  return tuple(output_paths_gcs)
              else:
                  output_paths = []
                  data_path = os.path.join(config['processed_path'], config['processed_data'][0])

                  # Train ----------------------------------------------------------------------------------------------------
                  train_data = load_data(input_data=data_path, mode=mode)
                  y_train = train_data[[config['target']]]
                  x_train = train_data[train_data.columns.difference([config['target']])]

                  feats_generator.fit(data=x_train, est_param=config['est_params'][0])
                  x_train_tf_idf_df = feats_generator.transform(data=x_train, est_param=config['est_params'][0])

                  feats_generator.fit(data=x_train_tf_idf_df, est_param=config['est_params'][1])
                  x_train_scaled = feats_generator.transform(data=x_train_tf_idf_df, est_param=config['est_params'][1])

                  train_path = save_data(x_df=x_train_scaled, y_df=y_train, path=config['featured_path'],
                                         out_data=config['featured_data'][0], mode=mode, bucket=bucket)
                  output_paths.append(train_path)

                  # Test - Val -----------------------------------------------------------------------------------------------
                  for input_path, out_filename in zip(config['processed_data'][1:], config['featured_data'][1:]):
                      data_path = os.path.join(config['processed_path'], input_path)
                      data = load_data(input_data=data_path, mode=mode)
                      y = data[[config['target']]]
                      x = data[data.columns.difference([config['target']])]

                      x_tf_idf_matrix = feats_generator.transform(data=x, est_param=config['est_params'][0])
                      x_scaled = feats_generator.transform(data=x_tf_idf_matrix, est_param=config['est_params'][1])

                      x_path = save_data(x_df=x_scaled, y_df=y, path=config['featured_path'],
                                                 out_data=out_filename, mode=mode, bucket=bucket)

                      output_paths.append(x_path)
                  return tuple(output_paths)

          except RuntimeError as error:
              logging.info(error)
              sys.exit(1)

      import argparse
      _parser = argparse.ArgumentParser(prog='Run generate features', description='')
      _parser.add_argument("--config", dest="config", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--mode", dest="mode", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--bucket", dest="bucket", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--train-path", dest="train_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--test-path", dest="test_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--val-path", dest="val_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=3)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = run_generate_features(**_parsed_args)

      _output_serializers = [
          str,
          str,
          str,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --config
    - {inputValue: config}
    - --mode
    - {inputValue: mode}
    - --bucket
    - {inputValue: bucket}
    - --train-path
    - {inputValue: train_path}
    - --test-path
    - {inputValue: test_path}
    - --val-path
    - {inputValue: val_path}
    - '----output-paths'
    - {outputPath: train}
    - {outputPath: test}
    - {outputPath: val}
